#!/usr/bin/env qore
# -*- mode: qore; indent-tabs-mode: nil -*-

%require-types
%strict-args
%new-style
%enable-all-warnings

%exec-class BB_TestSftpJob

%requires QorusInterfaceTest
%requires Util
%requires FsUtil

class BB_TestSftpJob inherits QorusJobTest {
    private {
        #! for local files
        TmpDir local_tmpdir();

        #! for SFTP files
        TmpDir sftp_tmpdir();

        string sftp_conn_name = get_random_string(20);

         #! command-line options
        const MyOpts = Opts + {
            "privkey": "k,privkey=s",
        };

        const JobName = "bb-test-sftp-job";

        const WorkflowName = "BB-TEST-SFTP-WORKFLOW";

        const WorkflowOrderMapper = "bb-test-sftp-job";

        const TestData = "testing - " + get_random_string();
    }

    constructor() : QorusJobTest(JobName, "1.0", \ARGV, MyOpts) {
        addTestCase("SFTP job FS test", \sftpJobFsTest());
        addTestCase("SFTP job transfer test", \sftpJobTransferTest());
        set_return_value(main());
    }

private usageIntern(int offset = OffsetColumn) {
        TestReporter::usageIntern(OffsetColumn);
        printOption("-k,--privkey", "the private key to use for the local SFTP connection", offset);
    }

    globalSetUp() {
        # create SFTP connection
        {
            # SFTP connection URL
            string url = "sftp://";
            hash<auto> opts = {};
            if (m_options.privkey) {
                opts += {
                    "keyfile": m_options.privkey,
                };
            } else if (is_file(ENV.HOME + "/.ssh/id_rsa.old")) {
                opts += {
                    "keyfile": ENV.HOME + "/.ssh/id_rsa.old",
                };
            } else if (is_file(ENV.HOME + "/.ssh/id_rsa")) {
                opts += {
                    "keyfile": ENV.HOME + "/.ssh/id_rsa",
                };
            } else if (ENV.SFTP_USER && ENV.SFTP_PASS) {
                url += sprintf("%s:%s@", ENV.SFTP_USER, ENV.SFTP_PASS);
            }
            url += "localhost/" + sftp_tmpdir.path;
            qrest.post("remote/user", {
                "name": sftp_conn_name,
                "desc": "test connection for SFTP test job",
                "url": url,
                "options": opts,
            });
        }

        # configure job
        hash<auto> job_config = {
            "sftp-polling-connection-name": sftp_conn_name,
            "sftp-polling-mask": "*.txt",
            "create-workflow-name": WorkflowName,
            "create-workflow-order-mapper": WorkflowOrderMapper,
        };
        map qrest.put("jobs/" + JobName + "/config/" + $1.key, {"value": $1.value}), job_config.pairIterator();

        # ensure default configuration
        map qrest.del("jobs/" + JobName + "/config/" + $1.name), qrest.get("jobs/bb-test-sftp-job/config"),
            !job_config{$1.name} && ((exists $1.default_value && $1.default_value != $1.value)
                                     || (!exists $1.default_value && exists $1.value));

        # start test workflow
        qrest.put("workflows/" + WorkflowName + "/setAutostart", {"autostart": 1});
    }

    globalTearDown() {
        # stop test workflow
        qrest.put("workflows/" + WorkflowName + "/setAutostart", {"autostart": 0});

        # unconfigure job
        qrest.del("jobs/" + JobName + "/config/create-workflow-order-mapper");
        qrest.del("jobs/" + JobName + "/config/create-workflow-name");
        qrest.del("jobs/" + JobName + "/config/sftp-polling-file-connection");
        qrest.del("jobs/" + JobName + "/config/sftp-polling-mask");
        qrest.del("jobs/" + JobName + "/config/sftp-polling-connection-name");

        # delete sftp connection
        qrest.del("remote/user/" + sftp_conn_name);
    }

    sftpJobFsTest() {
        string file_conn_name = get_random_string(20);

        # create file connection
        qrest.post("remote/user", {
            "name": file_conn_name,
            "desc": "test connection for SFTP test job",
            "url": "file://" + local_tmpdir.path,
        });
        on_exit {
            # delete connection
            qrest.del("remote/user/" + file_conn_name);
        }

        hash<auto> job_config = {
            "sftp-polling-file-connection": file_conn_name,
        };
        map qrest.put("jobs/" + JobName + "/config/" + $1.key, {"value": $1.value}), job_config.pairIterator();
        on_exit {
            map qrest.del("jobs/" + JobName + "/config/" + $1), keys job_config;
        }

        # create example file
        string filename;
        string file_path;
        {
            hash<TmpFileHash> tmp_file = make_tmp_file("test-", ".txt", sftp_tmpdir.path);
            tmp_file.file.write(TestData);
            filename = basename(tmp_file.path);
            file_path = tmp_file.path;
        }

        # make sure files that don't match the mask are not polled
        TmpFile ignore_file("test-", ".ignore", sftp_tmpdir.path);

        RunJobResult job(OMQ::StatComplete);
        exec(job);

        int jiid = job.getJobResult().job_instanceid;
        hash<auto> results = qrest.get("jobresults/" + jiid).info[0];
        assertEq(OMQ::StatBlocked, results.order_status);
        int wfiid = results.workflow_instanceid;
        # wait for workflow order to be COMPLETE
        WaitForWfiid wait(wfiid, NOTHING, 5s);
        wait.run(self);
        hash<auto> order = qrest.get("orders/" + wfiid);
        assertEq(filename, order.keys.filename);
        assertEq(filename, order.staticdata.name);
        assertEq(filename, order.staticdata.filepath);
        assertEq(Type::Date, order.staticdata.transfer_time.type());
        assertEq(Type::Date, order.staticdata.atime.type());
        assertEq(Type::Date, order.staticdata.mtime.type());
        assertEq("REGULAR", order.staticdata.type);
        assertEq(TestData, order.dynamicdata."data");

        assertTrue(is_file(ignore_file.path));

        # test complex duplicate handling
        {
            # for duplicate files
            TmpDir dup_tmpdir();
            string dup_file_conn_name = get_random_string(20);

            # create file connection
            qrest.post("remote/user", {
                "name": dup_file_conn_name,
                "desc": "test connection for SFTP test job",
                "url": "file://" + dup_tmpdir.path,
            });
            on_exit {
                # delete connection
                qrest.del("remote/user/" + dup_file_conn_name);
            }

            hash<auto> dup_config = {
                "sftp-polling-duplicate-file-connection": dup_file_conn_name,
                "sftp-polling-duplicate-workflow-name": "BB-TEST-SFTP-WORKFLOW-DUP",
                "sftp-polling-duplicate-order-mapper": "bb-test-sftp-job-duplicate",
            };
            map qrest.put("jobs/" + JobName + "/config/" + $1.key, {"value": $1.value}), dup_config.pairIterator();
            on_exit {
                # ensure default configuration
                map qrest.del("jobs/" + JobName + "/config/" + $1), keys dup_config;
            }

            {
                File f();
                f.open2(file_path, O_CREAT | O_WRONLY | O_TRUNC);
                f.write(TestData);
            }
            exec(job);
            int jiid2 = job.getJobResult().job_instanceid;
            assertNeq(jiid, jiid2);
            results = qrest.get("jobresults/" + jiid2).info[0];
            int wfiid2 = results.workflow_instanceid;
            assertEq(wfiid, wfiid2);
            assertTrue(results.duplicate);
            assertEq(OMQ::StatComplete, results.order_status);
        }
    }

    sftpJobTransferTest() {
        # create example file
        string filename;
        string file_path;
        {
            hash<TmpFileHash> tmp_file = make_tmp_file("test-", ".txt", sftp_tmpdir.path);
            tmp_file.file.write(TestData);
            filename = basename(tmp_file.path);
            file_path = tmp_file.path;
        }

        # make sure files that don't match the mask are not polled
        TmpFile ignore_file("test-", ".ignore", sftp_tmpdir.path);

        # start test workflow
        qrest.put("workflows/" + WorkflowName + "/setAutostart", {"autostart": 1});
        on_exit {
            qrest.put("workflows/" + WorkflowName + "/setAutostart", {"autostart": 0});
        }

        RunJobResult job(OMQ::StatComplete);
        exec(job);

        int jiid = job.getJobResult().job_instanceid;
        hash<auto> results = qrest.get("jobresults/" + jiid).info[0];
        assertEq(OMQ::StatBlocked, results.order_status);
        int wfiid = results.workflow_instanceid;
        # wait for workflow order to be COMPLETE
        WaitForWfiid wait(wfiid, NOTHING, 5s);
        wait.run(self);
        hash<auto> order = qrest.get("orders/" + wfiid);
        assertEq(filename, order.keys.filename);
        assertEq(filename, order.staticdata.name);
        assertEq(filename, order.staticdata.filepath);
        assertEq(Type::Date, order.staticdata.transfer_time.type());
        assertEq(Type::Date, order.staticdata.atime.type());
        assertEq(Type::Date, order.staticdata.mtime.type());
        assertEq("REGULAR", order.staticdata.type);
        assertEq(TestData, order.staticdata."data".toString());

        assertTrue(is_file(ignore_file.path));

        # test simple duplicate handling; make sure the same workflow_instanceid is returned for a file with the same name
        {
            File f();
            f.open2(file_path, O_CREAT | O_WRONLY | O_TRUNC);
            f.write(TestData);
        }
        exec(job);
        int jiid2 = job.getJobResult().job_instanceid;
        assertNeq(jiid, jiid2);
        results = qrest.get("jobresults/" + jiid2).info[0];
        int wfiid2 = results.workflow_instanceid;
        assertEq(wfiid, wfiid2);
        assertTrue(results.duplicate);
        assertEq(OMQ::StatComplete, results.order_status);
    }
}