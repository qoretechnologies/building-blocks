# This is a generated file, don't edit!
type: class
name: BBM_KafkaConsumer
desc: >-
    ## Summary


    **[Kafka](https://kafka.apache.org/)** message consumer building block;
    provides a Kafka message event source to Qorus.


    This building block class is designed to be used in a Qorus service.


    ## Connectors


    ### Event Connector `event`


    Provides Kafka messages as events.


    Event connectors can only be used in Qorus services.


    ### Input/Output Connector `start`


    Starts listening to Kafka messages; meant to be assocated with a service's
    `start()` method.


    Input data is ignored; returns `true` if the Kafka listening thread was
    started, `false` immediately if already running.  This connector returns
    `true` at the end of listening; the `start()` method runs for the lifetime
    of the object until stopped.


    ### Input/Output Connector `stop`


    Stops listening to Kafka messages; means to be associated with a service's
    `stop()` method.


    Input data is ignored; returns `null` (`NOTHING` if called from Qore, `None`
    if called from Python).
lang: java
author:
  - Qore Technologies, s.r.o.
class-connectors:
  - name: event
    type: event
    method: eventLoop
    output-provider:
        type: type
        name: qoretechnologies
        can_manage_fields: false
        path: /building-blocks/kafka/recv-message
  - name: start
    type: input-output
    method: start
  - name: stop
    type: input-output
    method: stop
requires:
  - BBM_JavaConfig
tags:
    classpath: $OMQ_DIR/user/building-blocks/kafka/jar/kafka-clients-2.6.0.jar:$OMQ_DIR/user/building-blocks/kafka/jar/slf4j-api-1.7.30.jar:$OMQ_DIR/user/building-blocks/kafka/jar/jackson-databind-2.10.2.jar:$OMQ_DIR/user/building-blocks/kafka/jar/jackson-core-2.10.2.jar:$OMQ_DIR/user/building-blocks/kafka/jar/jackson-annotations-2.10.2.jar
version: '1.0'
code: bbm_kafkaconsumer_1_0_class/BBM_KafkaConsumer.java
config-items:
  - name: kafka-conf-bootstrap.servers
    description: >-
        **Kafka** servers
    
    
        A comma-separated list of host/port pairs to use for establishing the
        initial connection to the Kafka cluster. The client will make use of all
        servers irrespective of which servers are specified here for bootstrapping;
        this list only impacts the initial hosts used to discover the full set of
        servers.
    
    
        This list should be in the form `host1:port1,host2:port2,...`
    
    
        Since these servers are just used for the initial connection to discover the
        full cluster membership (which may change dynamically), this list need not
        contain the full set of servers (you may want more than one, though, in case
        a server is down).
    config_group: Kafka Consumer Main
  - name: kafka-topics
    description: One or more topics to subscribe to; must be a list of strings
    config_group: Kafka Consumer Main
    type: list
  - name: kafka-conf-key.deserializer
    default_value:
        "org.apache.kafka.common.serialization.StringDeserializer"
    description: >-
        Serializer class for key that implements the
        `org.apache.kafka.common.serialization.Deserializer` interface
    config_group: Kafka Consumer Main
  - name: kafka-conf-value.deserializer
    default_value:
        "org.apache.kafka.common.serialization.StringDeserializer"
    description: >-
    
        Serializer class for value that implements the
        `org.apache.kafka.common.serialization.Deserializer` interface.
    config_group: Kafka Consumer Main
  - name: kafka-conf-fetch.min.bytes
    default_value:
        1
    description: >-
        The minimum amount of data the server should return for a fetch request.
    
    
        If insufficient data is available the request will wait for that much data
        to accumulate before answering the request.
    
    
        The default setting of 1 byte means that fetch requests are answered as soon
        as a single byte of data is available or the fetch request times out waiting
        for data to arrive.
    
    
        Setting this to something greater than `1` will cause the server to wait for
        larger amounts of data to accumulate which can improve server throughput a
        bit at the cost of some additional latency.
    config_group: Kafka Consumer High-Priority Options
    type: "*int"
  - name: kafka-conf-group.id
    default_value:
        null
    description: >-
        A unique string that identifies the consumer group this consumer belongs to.
    
    
        This property is required if the consumer uses either the group management
        functionality by using `subscribe(topic)` or the Kafka-based offset
        management strategy.
    config_group: Kafka Consumer High-Priority Options
    type: "*string"
  - name: kafka-conf-heartbeat.interval.ms
    default_value:
        3000
    description: >-
        The expected time between heartbeats to the consumer coordinator when using
        Kafka's group management facilities.
    
    
        Heartbeats are used to ensure that the consumer's session stays active and
        to facilitate rebalancing when new consumers join or leave the group.
    
    
        The value must be set lower than `session.timeout.ms`, but typically should
        be set no higher than 1/3 of that value.
    
    
        It can be adjusted even lower to control the expected time for normal
        rebalances.
    config_group: Kafka Consumer High-Priority Options
    type: "*int"
  - name: kafka-conf-max.partition.fetch.bytes
    default_value:
        1048576
    description: >-
        The maximum amount of data per-partition the server will return.
    
    
        Records are fetched in batches by the consumer.
    
    
        If the first record batch in the first non-empty partition of the fetch is
        larger than this limit, the batch will still be returned to ensure that the
        consumer can make progress.
    
    
        The maximum record batch size accepted by the broker is defined via
        `message.max.bytes` (broker config) or `max.message.bytes` (topic config).
    
    
        See `fetch.max.bytes` for limiting the consumer request size.
    config_group: Kafka Consumer High-Priority Options
    type: "*int"
  - name: kafka-conf-session.timeout.ms
    default_value:
        10000
    description: >-
        The timeout used to detect client failures when using Kafka's group
        management facility.
    
    
        The client sends periodic heartbeats to indicate its liveness to the broker.
    
    
        If no heartbeats are received by the broker before the expiration of this
        session timeout, then the broker will remove this client from the group and
        initiate a rebalance.
    
    
        Note that the value must be in the allowable range as configured in the
        broker configuration by `group.min.session.timeout.ms` and
        `group.max.session.timeout.ms`.
    config_group: Kafka Consumer High-Priority Options
    type: "*int"
  - name: kafka-conf-ssl.key.password
    default_value:
        null
    description: The password of the private key in the key store file.
    config_group: Kafka Consumer SSL Options
    type: "*string"
    sensitive: true
  - name: kafka-conf-ssl.keystore.location
    default_value:
        null
    description: >-
        The location of the key store file. This is optional for clients and can be
        used for two-way authentication for clients.
    config_group: Kafka Consumer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.keystore.password
    default_value:
        null
    description: >-
        The store password for the key store file. This is optional for client and
        only needed if `ssl.keystore.location` is configured.
    config_group: Kafka Consumer SSL Options
    type: "*string"
    sensitive: true
  - name: kafka-conf-ssl.keystore.type
    default_value:
        null
    description: The file format of the key store file.
    config_group: Kafka Consumer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.truststore.location
    default_value:
        null
    description: The location of the trust store file.
    config_group: Kafka Consumer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.truststore.password
    default_value:
        null
    description: >-
        The password for the trust store file. If a password is not set access to
        the truststore is still available, but integrity checking is disabled.
    config_group: Kafka Consumer SSL Options
    type: "*string"
    sensitive: true
  - name: kafka-conf-ssl.protocol
    default_value:
        null
    description: >-
        The SSL protocol used to generate the `SSLContext`.
    
    
        The default is `TLSv1.3` when running with Java 11 or newer, `TLSv1.2`
        otherwise.
    
    
        This value should be fine for most use cases. Allowed values in recent JVMs
        are `TLSv1.2` and `TLSv1.3`.
    
    
        `TLS`, `TLSv1.1`, `SSL`, `SSLv2` and `SSLv3` may be supported in older JVMs,
        but their usage is discouraged due to known security vulnerabilities.
    
    
        With the default value for this config and `ssl.enabled.protocols`, clients
        will downgrade to `TLSv1.2` if the server does not support `TLSv1.3`.
    
    
        If this config is set to `TLSv1.2`, clients will not use `TLSv1.3` even if
        it is one of the values in `ssl.enabled.protocols` and the server only
        supports `TLSv1.3`.
    config_group: Kafka Consumer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.provider
    default_value:
        null
    description: >-
        The name of the security provider used for SSL connections. Default value is
        the default security provider of the JVM.
    config_group: Kafka Consumer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.truststore.type
    default_value:
        null
    description: The file format of the trust store file.
    config_group: Kafka Consumer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.enabled.protocols
    default_value:
        null
    description: >-
        The comma-separated list of protocols enabled for SSL connections.
    
    
        The default is `TLSv1.2,TLSv1.3` when running with Java 11 or newer,
        `TLSv1.2` otherwise.
    
    
        With the default value for Java 11, clients and servers will prefer
        `TLSv1.3` if both support it and fallback to `TLSv1.2` otherwise (assuming
        both support at least `TLSv1.2`). This default should be fine for most
        cases. Also see the config documentation for `ssl.protocol`.
    config_group: Kafka Consumer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.cipher.suites
    default_value:
        null
    description: >-
        A comma-separated list of cipher suites. This is a named combination of
        authentication, encryption, MAC and key exchange algorithm used to negotiate
        the security settings for a network connection using TLS or SSL network
        protocol.
    
    
        By default all the available cipher suites are supported.
    config_group: Kafka Consumer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.endpoint.identification.algorithm
    default_value:
        "https"
    description: >-
        The endpoint identification algorithm to validate server hostname using
        server certificate.
    config_group: Kafka Consumer Low-Priority Options
    type: "*string"
  - name: kafka-conf-ssl.engine.factory.class
    default_value:
        null
    description: >-
        The class of type `org.apache.kafka.common.security.auth.SslEngineFactory`
        to provide `SSLEngine` objects.
    
    
        Default value is
        `org.apache.kafka.common.security.ssl.DefaultSslEngineFactory`
    config_group: Kafka Consumer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.keymanager.algorithm
    default_value:
        "SunX509"
    description: >-
        The algorithm used by key manager factory for SSL connections. The default
        value is the key manager factory algorithm configured for the Java Virtual
        Machine.
    config_group: Kafka Consumer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.secure.random.implementation
    default_value:
        null
    description: The SecureRandom PRNG implementation to use for SSL cryptography operations.
    config_group: Kafka Consumer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.trustmanager.algorithm
    default_value:
        "PKIX"
    description: >-
        The algorithm used by trust manager factory for SSL connections. The default
        value is the trust manager factory algorithm configured for the Java Virtual
        Machine.
    config_group: Kafka Consumer SSL Options
    type: "*string"
  - name: kafka-conf-sasl.client.callback.handler.class
    default_value:
        null
    description: >-
        The fully qualified name of a SASL client callback handler class that
        implements the `AuthenticateCallbackHandler` interface.
    config_group: Kafka Consumer SASL Options
    type: "*string"
  - name: kafka-conf-sasl.jaas.config
    default_value:
        null
    description: >-
        JAAS login context parameters for SASL connections in the format used by
        JAAS configuration files.
    
    
        JAAS configuration file format is described here. The format for the value
        is: `loginModuleClass controlFlag (optionName=optionValue)*;`.
    
    
        For brokers, the config must be prefixed with listener prefix and SASL
        mechanism name in lower-case.
    
    
        For example,
        `listener.name.sasl_ssl.scram-sha-256.sasl.jaas.config=com.example.ScramLoginModule
        required;`
    config_group: Kafka Consumer SASL Options
    type: "*string"
    sensitive: true
  - name: kafka-conf-sasl.kerberos.service.name
    default_value:
        null
    description: >-
        The Kerberos principal name that Kafka runs as. This can be defined either
        in Kafka's JAAS config or in Kafka's config.
    config_group: Kafka Consumer SASL Options
    type: "*string"
  - name: kafka-conf-sasl.login.callback.handler.class
    default_value:
        null
    description: >-
        The fully qualified name of a SASL login callback handler class that
        implements the `AuthenticateCallbackHandler` interface.
    
    
        For brokers, the login callback handler config must be prefixed with the
        listener prefix and the SASL mechanism name in lower-case.
    
    
        For example,
        `listener.name.sasl_ssl.scram-sha-256.sasl.login.callback.handler.class=com.example.CustomScramLoginCallbackHandler`
    config_group: Kafka Consumer SASL Options
    type: "*string"
  - name: kafka-conf-sasl.login.class
    default_value:
        null
    description: >-
        The fully qualified name of a class that implements the Login interface. For
        brokers, the login config must be prefixed with the listener prefix and the
        SASL mechanism name in lower-case.
    
    
        For example,
        `listener.name.sasl_ssl.scram-sha-256.sasl.login.class=com.example.CustomScramLogin`
    config_group: Kafka Consumer SASL Options
    type: "*string"
  - name: kafka-conf-sasl.mechanism
    default_value:
        "GSSAPI"
    description: >-
        SASL mechanism used for client connections. This may be any mechanism for
        which a security provider is available. GSSAPI is the default mechanism.
    config_group: Kafka Consumer SASL Options
  - name: kafka-conf-sasl.kerberos.kinit.cmd
    default_value:
        "/usr/bin/kinit"
    description: Kerberos kinit command path.
    config_group: Kafka Consumer SASL Options
    type: "*string"
  - name: kafka-conf-sasl.kerberos.min.time.before.relogin
    default_value:
        60000
    description: Login thread sleep time between refresh attempts.
    config_group: Kafka Consumer SASL Options
    type: "*int"
  - name: kafka-conf-sasl.kerberos.ticket.renew.jitter
    default_value:
        0.05
    description: Percentage of random jitter added to the renewal time.
    config_group: Kafka Consumer SASL Options
    type: "*float"
  - name: kafka-conf-sasl.kerberos.ticket.renew.window.factor
    default_value:
        0.8
    description: >-
        Login thread will sleep until the specified window factor of time from last
        refresh to ticket's expiry has been reached, at which time it will try to
        renew the ticket.
    config_group: Kafka Consumer SASL Options
    type: "*float"
  - name: kafka-conf-sasl.login.refresh.buffer.seconds
    default_value:
        300
    description: >-
        The amount of buffer time before credential expiration to maintain when
        refreshing a credential, in seconds.
    
    
        If a refresh would otherwise occur closer to expiration than the number of
        buffer seconds then the refresh will be moved up to maintain as much of the
        buffer time as possible.
    
    
        Legal values are between `0` and `3600` (1 hour); a default value of `300`
        (5 minutes) is used if no value is specified.
    
    
        This value and `sasl.login.refresh.min.period.seconds` are both ignored if
        their sum exceeds the remaining lifetime of a credential.
    
    
        Currently applies only to `OAUTHBEARER`.
    config_group: Kafka Consumer SASL Options
    type: "*int"
  - name: kafka-conf-sasl.login.refresh.min.period.seconds
    default_value:
        60
    description: >-
        The desired minimum time for the login refresh thread to wait before
        refreshing a credential, in seconds.
    
    
        Legal values are between `0` and `900` (15 minutes); a default value of `60`
        (1 minute) is used if no value is specified.
    
    
        This value and `sasl.login.refresh.buffer.seconds` are both ignored if their
        sum exceeds the remaining lifetime of a credential.
    
    
        Currently applies only to `OAUTHBEARER`.
    config_group: Kafka Consumer SASL Options
    type: "*int"
  - name: kafka-conf-sasl.login.refresh.window.factor
    default_value:
        0.8
    description: >-
        Login refresh thread will sleep until the specified window factor relative
        to the credential's lifetime has been reached, at which time it will try to
        refresh the credential.
    
    
        Legal values are between `0.5` (50%) and `1.0` (100%) inclusive; a default
        value of `0.8` (80%) is used if no value is specified.
    
    
        Currently applies only to `OAUTHBEARER`.
    config_group: Kafka Consumer SASL Options
    type: "*float"
  - name: kafka-conf-sasl.login.refresh.window.jitter
    default_value:
        0.05
    description: >-
        The maximum amount of random jitter relative to the credential's lifetime
        that is added to the login refresh thread's sleep time.
    
    
        Legal values are between `0` and `0.25` (25%) inclusive; a default value of
        `0.05` (5%) is used if no value is specified.
    
    
        Currently applies only to `OAUTHBEARER`.
    config_group: Kafka Consumer SASL Options
    type: "*float"
  - name: kafka-conf-batch.size
    default_value:
        null
    description: >-
        The producer will attempt to batch records together into fewer requests
        whenever multiple records are being sent to the same partition. This helps
        performance on both the client and the server. This configuration controls
        the default batch size in bytes.
    
    
        No attempt will be made to batch records larger than this size.
    
    
        Requests sent to brokers will contain multiple batches, one for each
        partition with data available to be sent.
    
    
        A small batch size will make batching less common and may reduce throughput
        (a batch size of zero will disable batching entirely). A very large batch
        size may use memory a bit more wastefully as we will always allocate a
        buffer of the specified batch size in anticipation of additional records.
    config_group: Kafka Consumer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-allow.auto.create.topics
    default_value:
        true
    description: >-
        Allow automatic topic creation on the broker when subscribing to or
        assigning a topic.
    
    
        A topic being subscribed to will be automatically created only if the broker
        allows for it using `auto.create.topics.enable` on the broker.
    
    
        This configuration must be set to `false` when using brokers older than
        `0.11.0`.
    config_group: Kafka Consumer Medium-Priority Options
    type: "*bool"
  - name: kafka-conf-auto.offset.reset
    default_value:
        "latest"
    description: >-
        What to do when there is no initial offset in Kafka or if the current offset
        does not exist anymore on the server (e.g. data has been deleted):
    
        - `latest`: automatically reset the offset to the latest offset
    
        - `earliest`: automatically reset the offset to the earliest offset
    
        - `none`: throw exception to the consumer if no previous offset is found for
        the
          consumer's group
    config_group: Kafka Consumer Medium-Priority Options
    allowed_values:
      - "latest"
      - "earliest"
      - "none"
  - name: kafka-conf-client.dns.lookup
    default_value:
        "use_all_dns_ips"
    description: >-
        Controls how the client uses DNS lookups: - `use_all_dns_ips`: Connect to
        each returned IP address in sequence until a successful connection is
        established. After a disconnection, the next IP is used.
    
    
        Once all IPs have been used once, the client resolves the IP(s) from the
        hostname again (both the JVM and the OS cache DNS name lookups, however)
    
        - `resolve_canonical_bootstrap_servers_only`: Resolve each bootstrap address
          into a list of canonical names. After the bootstrap phase, this behaves the
          same as `use_all_dns_ips`
    
        - `default`: (deprecated) Attempt to connect to the first IP address
        returned
          by the lookup, even if the lookup returns multiple IP addresses
    config_group: Kafka Consumer Medium-Priority Options
    allowed_values:
      - "default"
      - "use_all_dns_ips"
      - "resolve_canonical_bootstrap_servers_only"
  - name: kafka-conf-connections.max.idle.ms
    default_value:
        540000
    description: >-
        Close idle connections after the number of milliseconds specified by this
        config.
    config_group: Kafka Consumer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-default.api.timeout.ms
    default_value:
        60000
    description: >-
        Specifies the timeout (in milliseconds) for client APIs.
    
    
        This configuration is used as the default timeout for all client operations
        that do not specify a `timeout` parameter.
    config_group: Kafka Consumer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-enable.auto.commit
    default_value:
        true
    description: >-
        If `true` the consumer's offset will be periodically committed in the
        background.
    config_group: Kafka Consumer Medium-Priority Options
    type: "*bool"
  - name: kafka-conf-exclude.internal.topics
    default_value:
        true
    description: >-
        Whether internal topics matching a subscribed pattern should be excluded
        from the subscription.
    
    
        It is always possible to explicitly subscribe to an internal topic.
    config_group: Kafka Consumer Medium-Priority Options
    type: "*bool"
  - name: kafka-conf-fetch.max.bytes
    default_value:
        52428800
    description: >-
        The maximum amount of data the server should return for a fetch request.
    
    
        Records are fetched in batches by the consumer, and if the first record
        batch in the first non-empty partition of the fetch is larger than this
        value, the record batch will still be returned to ensure that the consumer
        can make progress.
    
    
        As such, this is not a absolute maximum. The maximum record batch size
        accepted by the broker is defined via `message.max.bytes` (broker config) or
        `max.message.bytes` (topic config).
    
    
        Note that the consumer performs multiple fetches in parallel.
    config_group: Kafka Consumer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-group.instance.id
    default_value:
        null
    description: >-
        A unique identifier of the consumer instance provided by the end user. Only
        non-empty strings are permitted.
    
    
        If set, the consumer is treated as a static member, which means that only
        one instance with this ID is allowed in the consumer group at any time.
    
    
        This can be used in combination with a larger session timeout to avoid group
        rebalances caused by transient unavailability (e.g. process restarts).
    
    
        If not set, the consumer will join the group as a dynamic member, which is
        the traditional behavior.
    config_group: Kafka Consumer Medium-Priority Options
    type: "*string"
  - name: kafka-conf-isolation.level
    default_value:
        "read_uncommitted"
    description: >-
        Controls how to read messages written transactionally:
    
        - `read_committed`: `consumer.poll()` will only return transactional
        messages
          which have been committed
        - `read_uncommitted`: (the default) `consumer.poll()` will return all
        messages,
          even transactional messages which have been aborted. Non-transactional
          messages will be returned unconditionally in either mode.
    
    
        Messages will always be returned in offset order. Hence, in `read_committed`
        mode, `consumer.poll()` will only return messages up to the last stable
        offset (LSO), which is the one less than the offset of the first open
        transaction.
    
    
        In particular any messages appearing after messages belonging to ongoing
        transactions will be withheld until the relevant transaction has been
        completed.
    
    
        As a result, `read_committed` consumers will not be able to read up to the
        high watermark when there are inflight transactions.
    
        Further, when in `read_committed` the `seekToEnd()` method will return the
        LSO.
    config_group: Kafka Consumer Medium-Priority Options
    allowed_values:
      - "read_committed"
      - "read_uncommitted"
  - name: kafka-conf-max.poll.interval.ms
    default_value:
        300000
    description: >-
        The maximum delay between invocations of `poll()` when using consumer group
        management.
    
    
        This places an upper bound on the amount of time that the consumer can be
        idle before fetching more records.
    
    
        If `poll()` is not called before expiration of this timeout, then the
        consumer is considered failed and the group will rebalance in order to
        reassign the partitions to another member.
    
    
        For consumers using a non-null `group.instance.id` which reach this timeout,
        partitions will not be immediately reassigned. Instead, the consumer will
        stop sending heartbeats and partitions will be reassigned after the
        expiration of `session.timeout.ms`. This mirrors the behavior of a static
        consumer which has shutdown.
    config_group: Kafka Consumer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-max.poll.records
    default_value:
        500
    description: The maximum number of records returned in a single call to `poll()`.
    config_group: Kafka Consumer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-partition.assignment.strategy
    default_value:
        "org.apache.kafka.clients.consumer.RangeAssignor"
    description: >-
        One or more comma-separated class names or class types, ordered by
        preference, of supported partition assignment strategies that the client
        will use to distribute partition ownership amongst consumer instances when
        group management is used.
    
    
        In addition to the default class specified below, you can use the
        `org.apache.kafka.clients.consumer.RoundRobinAssignor` class for round robin
        assignments of partitions to consumers.
    
    
        Implementing the
        `org.apache.kafka.clients.consumer.ConsumerPartitionAssignor` interface
        allows you to plug in a custom assignmentstrategy.
    config_group: Kafka Consumer Medium-Priority Options
  - name: kafka-conf-receive.buffer.bytes
    default_value:
        65536
    description: |-
        The size of the TCP receive buffer (`SO_RCVBUF`) to use when reading data.
    
        If the value is `-1`, the OS default will be used.
    config_group: Kafka Consumer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-request.timeout.ms
    default_value:
        30000
    description: >-
        The configuration controls the maximum amount of time the client will wait
        for the response of a request.
    
    
        If the response is not received before the timeout elapses, the client will
        resend the request if necessary or fail the request if retries are
        exhausted.
    config_group: Kafka Consumer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-security.protocol
    default_value:
        "PLAINTEXT"
    description: Protocol used to communicate with brokers
    config_group: Kafka Consumer Medium-Priority Options
    allowed_values:
      - "PLAINTEXT"
      - "SSL"
      - "SASL_PLAINTEXT"
      - "SASL_SSL"
  - name: kafka-conf-send.buffer.bytes
    default_value:
        131072
    description: |-
        The size of the TCP send buffer (`SO_SNDBUF`) to use when sending data.
    
        If the value is `-1`, the OS default will be used.
    config_group: Kafka Consumer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-auto.commit.interval.ms
    default_value:
        5000
    description: >-
        The frequency in milliseconds that the consumer offsets are auto-committed
        to Kafka if `enable.auto.commit` is set to `true`.
    config_group: Kafka Consumer Low-Priority Options
    type: "*int"
  - name: kafka-conf-check.crcs
    default_value:
        true
    description: >-
        Automatically check the CRC32 of the records consumed.
    
    
        This ensures no on-the-wire or on-disk corruption to the messages occurred.
    
    
        This check adds some overhead, so it may be disabled in cases seeking
        extreme performance.
    config_group: Kafka Consumer Low-Priority Options
    type: "*bool"
  - name: kafka-conf-client.id
    default_value:
        null
    description: >-
        An id string to pass to the server when making requests. The purpose of this
        is to be able to track the source of requests beyond just ip/port by
        allowing a logical application name to be included in server-side request
        logging.
    config_group: Kafka Consumer Low-Priority Options
    type: "*string"
  - name: kafka-conf-client.rack
    default_value:
        null
    description: >-
        A rack identifier for this client. This can be any string value which
        indicates where this client is physically located.
    
    
        It corresponds with the broker config `broker.rack`
    config_group: Kafka Consumer Low-Priority Options
    type: "*string"
  - name: kafka-conf-fetch.max.wait.ms
    default_value:
        500
    description: >-
        The maximum amount of time the server will block before answering the fetch
        request if there isn't sufficient data to immediately satisfy the
        requirement given by `fetch.min.bytes`.
    config_group: Kafka Consumer Low-Priority Options
    type: "*int"
  - name: kafka-conf-interceptor.classes
    default_value:
        null
    description: >-
        A comma-separated list of classes to use as interceptors implementing the
        `org.apache.kafka.clients.consumerConsumerInterceptor` interface, allowing
        you to intercept (and possibly mutate) records received by the consumer.
    
    
        By default, there are no interceptors.
    config_group: Kafka Consumer Low-Priority Options
    type: "*string"
  - name: kafka-conf-metadata.max.age.ms
    default_value:
        300000
    description: >-
        The period of time in milliseconds after which we force a refresh of
        metadata even if we haven't seen any partition leadership changes to
        proactively discover any new brokers or partitions.
    config_group: Kafka Consumer Low-Priority Options
    type: "*int"
  - name: kafka-conf-metric.reporters
    default_value:
        null
    description: >-
        A comma-separated list of classes to use as metrics reporters implementing
        the `org.apache.kafka.common.metrics.MetricsReporter` interface, allowing
        plugging in classes that will be notified of new metric creation.
    
    
        The `JmxReporter` class is always included to register JMX statistics.
    config_group: Kafka Consumer Low-Priority Options
    type: "*string"
  - name: kafka-conf-metrics.num.samples
    default_value:
        2
    description: The number of samples maintained to compute metrics.
    config_group: Kafka Consumer Low-Priority Options
    type: "*int"
  - name: kafka-conf-metrics.recording.level
    default_value:
        "INFO"
    description: The highest recording level for metrics.
    config_group: Kafka Consumer Low-Priority Options
    allowed_values:
      - "INFO"
      - "DEBUG"
  - name: kafka-conf-metrics.sample.window.ms
    default_value:
        30000
    description: The window of time a metrics sample is computed over.
    config_group: Kafka Consumer Low-Priority Options
    type: "*int"
  - name: kafka-conf-reconnect.backoff.max.ms
    default_value:
        1000
    description: >-
        The maximum amount of time in milliseconds to wait when reconnecting to a
        broker that has repeatedly failed to connect.
    
    
        If provided, the backoff per host will increase exponentially for each
        consecutive connection failure, up to this maximum.
    
    
        After calculating the backoff increase, 20% random jitter is added to avoid
        connection storms.
    config_group: Kafka Consumer Low-Priority Options
    type: "*int"
  - name: kafka-conf-reconnect.backoff.ms
    default_value:
        50
    description: >-
        The base amount of time to wait before attempting to reconnect to a given
        host.
    
    
        This avoids repeatedly connecting to a host in a tight loop.
    
    
        This backoff applies to all connection attempts by the client to a broker.
    config_group: Kafka Consumer Low-Priority Options
    type: "*int"
  - name: kafka-conf-retry.backoff.ms
    default_value:
        100
    description: >-
        The amount of time to wait before attempting to retry a failed request to a
        given topic partition.
    
    
        This avoids repeatedly sending requests in a tight loop under some failure
        scenarios.
    config_group: Kafka Consumer Low-Priority Options
    type: "*int"
  - name: kafka-conf-security.providers
    default_value:
        null
    description: >-
        A comma-separated list of configurable creator classes each returning a
        provider implementing security algorithms.
    
    
        These classes should implement the
        `org.apache.kafka.common.security.auth.SecurityProviderCreator` interface.
    config_group: Kafka Consumer Low-Priority Options
    type: "*string"
