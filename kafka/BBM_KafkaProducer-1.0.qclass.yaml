# This is a generated file, don't edit!
type: class
name: BBM_KafkaProducer
desc: >-
    ## Summary


    **[Kafka](https://kafka.apache.org/)** message producer building block for
    sending Kafka messages from Qorus.


    ## Connectors


    ## Input/Output Connector `sendMessage`


    Sends a message synchronously; the input data is used to send the message
    and must correspond to the given input type.


    Output data provides information about the message sent.


    ## Input/Output Connector `sendMessageAsync`


    Sends a message asynchronously; the input data is used to send the message
    and must correspond to the given input type.


    Output data is a `Future` object regarding the asynchronous message sent.
lang: java
author:
  - Qore Technologies, s.r.o.
class-connectors:
  - name: sendMessage
    type: input-output
    method: sendMessage
    input-provider:
        type: type
        name: qoretechnologies
        can_manage_fields: false
        path: /building-blocks/kafka/send-message
    output-provider:
        type: type
        name: qoretechnologies
        can_manage_fields: false
        path: /building-blocks/kafka/record-metadata
  - name: sendMessageAsync
    type: input-output
    method: sendMessageAsync
requires:
  - BBM_JavaConfig
tags:
    classpath: $OMQ_DIR/user/building-blocks/kafka/jar/kafka-clients-2.6.0.jar:$OMQ_DIR/user/building-blocks/kafka/jar/slf4j-api-1.7.30.jar:$OMQ_DIR/user/building-blocks/kafka/jar/jackson-databind-2.10.2.jar:$OMQ_DIR/user/building-blocks/kafka/jar/jackson-core-2.10.2.jar:$OMQ_DIR/user/building-blocks/kafka/jar/jackson-annotations-2.10.2.jar
version: '1.0'
code: bbm_kafkaproducer_1_0_class/BBM_KafkaProducer.java
config-items:
  - name: kafka-conf-bootstrap.servers
    description: >-
        **Kafka** servers


        A comma-separated list of host/port pairs to use for establishing the
        initial connection to the Kafka cluster. The client will make use of all
        servers irrespective of which servers are specified here for bootstrapping;
        this list only impacts the initial hosts used to discover the full set of
        servers.


        This list should be in the form `host1:port1,host2:port2,...`


        Since these servers are just used for the initial connection to discover the
        full cluster membership (which may change dynamically), this list need not
        contain the full set of servers (you may want more than one, though, in case
        a server is down).
    config_group: Kafka Producer Main
  - name: kafka-conf-acks
    default_value:
        "1"
    description: >-
        - `0`: The producer will not wait for any acknowledgment from the server at
          all. The record will be immediately added to the socket buffer and
          considered sent. No guarantee can be made that the server has received the
          record in this case, and the `retries` configuration will not take effect
          (as the client won't generally know of any failures). The offset given back
          for each record will always be set to `-1`.

        - `1`: The leader will write the record to its local log but will respond
          without awaiting full acknowledgement from all followers. In this case
          should the leader fail immediately after acknowledging the record but
          before the followers have replicated it then the record will be lost.

        - `all`: This means the leader will wait for the full set of in-sync
        replicas
          to acknowledge the record. This guarantees that the record will not be lost
          as long as at least one in-sync replica remains alive. This is the strongest
          available guarantee. This is equivalent to the `acks=-1` setting.
    config_group: Kafka Producer Main
    allowed_values:
      - "0"
      - "1"
      - "all"
  - name: kafka-conf-key.serializer
    default_value:
        "org.apache.kafka.common.serialization.StringSerializer"
    description: >-
        Serializer class for key that implements the
        `org.apache.kafka.common.serialization.Serializer` interface
    config_group: Kafka Producer Main
  - name: kafka-conf-value.serializer
    default_value:
        "org.apache.kafka.common.serialization.StringSerializer"
    description: >-

        Serializer class for value that implements the
        `org.apache.kafka.common.serialization.Serializer` interface.
    config_group: Kafka Producer Main
  - name: kafka-conf-buffer.memory
    default_value:
        null
    description: >-
        The total bytes of memory the producer can use to buffer records waiting to
        be sent to the server. If records are sent faster than they can be delivered
        to the server the producer will block for `max.block.ms` after which it will
        throw an exception.


        This setting should correspond roughly to the total memory the producer will
        use, but is not a hard bound since not all memory the producer uses is used
        for buffering. Some additional memory will be used for compression (if
        compression is enabled) as well as for maintaining in-flight requests.
    config_group: Kafka Producer High-Priority Options
    type: "*int"
  - name: kafka-conf-compression.type
    default_value:
        "none"
    description: >-
        The compression type for all data generated by the producer. The default is
        `none` (i.e. no compression). Compression is of full batches of data, so the
        efficacy of batching will also impact the compression ratio (more batching
        means better compression).
    config_group: Kafka Producer High-Priority Options
    allowed_values:
      - "none"
      - "gzip"
      - "snappy"
      - "lz4"
      - "zstd"
  - name: kafka-conf-
    default_value:
        null
    description: >-
        Setting a value greater than zero will cause the client to resend any record
        whose send fails with a potentially transient error. Note that this retry is
        no different than if the client resent the record upon receiving the error.


        Allowing retries without setting `max.in.flight.requests.per.connection` to
        `1` will potentially change the ordering of records because if two batches
        are sent to a single partition, and the first fails and is retried but the
        second succeeds, then the records in the second batch may appear first.


        Note additionally that produce requests will be failed before the number of
        retries has been exhausted if the timeout configured by
        `delivery.timeout.ms` expires first before successful acknowledgement. Users
        should generally prefer to leave this config unset and instead use
        `delivery.timeout.ms` to control retry behavior.
    config_group: Kafka Producer High-Priority Options
    type: "*int"
  - name: kafka-conf-ssl.key.password
    default_value:
        null
    description: The password of the private key in the key store file.
    config_group: Kafka Producer SSL Options
    type: "*string"
    sensitive: true
  - name: kafka-conf-ssl.keystore.location
    default_value:
        null
    description: >-
        The location of the key store file. This is optional for clients and can be
        used for two-way authentication for clients.
    config_group: Kafka Producer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.keystore.password
    default_value:
        null
    description: >-
        The store password for the key store file. This is optional for client and
        only needed if `ssl.keystore.location` is configured.
    config_group: Kafka Producer SSL Options
    type: "*string"
    sensitive: true
  - name: kafka-conf-ssl.keystore.type
    default_value:
        null
    description: The file format of the key store file.
    config_group: Kafka Producer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.truststore.location
    default_value:
        null
    description: The location of the trust store file.
    config_group: Kafka Producer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.truststore.password
    default_value:
        null
    description: >-
        The password for the trust store file. If a password is not set access to
        the truststore is still available, but integrity checking is disabled.
    config_group: Kafka Producer SSL Options
    type: "*string"
    sensitive: true
  - name: kafka-conf-ssl.protocol
    default_value:
        null
    description: >-
        The SSL protocol used to generate the `SSLContext`.


        The default is `TLSv1.3` when running with Java 11 or newer, `TLSv1.2`
        otherwise.


        This value should be fine for most use cases. Allowed values in recent JVMs
        are `TLSv1.2` and `TLSv1.3`.


        `TLS`, `TLSv1.1`, `SSL`, `SSLv2` and `SSLv3` may be supported in older JVMs,
        but their usage is discouraged due to known security vulnerabilities.


        With the default value for this config and `ssl.enabled.protocols`, clients
        will downgrade to `TLSv1.2` if the server does not support `TLSv1.3`.


        If this config is set to `TLSv1.2`, clients will not use `TLSv1.3` even if
        it is one of the values in `ssl.enabled.protocols` and the server only
        supports `TLSv1.3`.
    config_group: Kafka Producer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.provider
    default_value:
        null
    description: >-
        The name of the security provider used for SSL connections. Default value is
        the default security provider of the JVM.
    config_group: Kafka Producer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.truststore.type
    default_value:
        null
    description: The file format of the trust store file.
    config_group: Kafka Producer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.enabled.protocols
    default_value:
        null
    description: >-
        The comma-separated list of protocols enabled for SSL connections.


        The default is `TLSv1.2,TLSv1.3` when running with Java 11 or newer,
        `TLSv1.2` otherwise.


        With the default value for Java 11, clients and servers will prefer
        `TLSv1.3` if both support it and fallback to `TLSv1.2` otherwise (assuming
        both support at least `TLSv1.2`). This default should be fine for most
        cases. Also see the config documentation for `ssl.protocol`.
    config_group: Kafka Producer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.cipher.suites
    default_value:
        null
    description: >-
        A comma-separated list of cipher suites. This is a named combination of
        authentication, encryption, MAC and key exchange algorithm used to negotiate
        the security settings for a network connection using TLS or SSL network
        protocol.


        By default all the available cipher suites are supported.
    config_group: Kafka Producer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.endpoint.identification.algorithm
    default_value:
        "https"
    description: >-
        The endpoint identification algorithm to validate server hostname using
        server certificate.
    config_group: Kafka Producer Low-Priority Options
    type: "*string"
  - name: kafka-conf-ssl.engine.factory.class
    default_value:
        null
    description: >-
        The class of type `org.apache.kafka.common.security.auth.SslEngineFactory`
        to provide `SSLEngine` objects.


        Default value is
        `org.apache.kafka.common.security.ssl.DefaultSslEngineFactory`
    config_group: Kafka Producer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.keymanager.algorithm
    default_value:
        "SunX509"
    description: >-
        The algorithm used by key manager factory for SSL connections. The default
        value is the key manager factory algorithm configured for the Java Virtual
        Machine.
    config_group: Kafka Producer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.secure.random.implementation
    default_value:
        null
    description: The SecureRandom PRNG implementation to use for SSL cryptography operations.
    config_group: Kafka Producer SSL Options
    type: "*string"
  - name: kafka-conf-ssl.trustmanager.algorithm
    default_value:
        "PKIX"
    description: >-
        The algorithm used by trust manager factory for SSL connections. The default
        value is the trust manager factory algorithm configured for the Java Virtual
        Machine.
    config_group: Kafka Producer SSL Options
    type: "*string"
  - name: kafka-conf-sasl.client.callback.handler.class
    default_value:
        null
    description: >-
        The fully qualified name of a SASL client callback handler class that
        implements the `AuthenticateCallbackHandler` interface.
    config_group: Kafka Producer SASL Options
    type: "*string"
  - name: kafka-conf-sasl.jaas.config
    default_value:
        null
    description: >-
        JAAS login context parameters for SASL connections in the format used by
        JAAS configuration files.


        JAAS configuration file format is described here. The format for the value
        is: `loginModuleClass controlFlag (optionName=optionValue)*;`.


        For brokers, the config must be prefixed with listener prefix and SASL
        mechanism name in lower-case.


        For example,
        `listener.name.sasl_ssl.scram-sha-256.sasl.jaas.config=com.example.ScramLoginModule
        required;`
    config_group: Kafka Producer SASL Options
    type: "*string"
    sensitive: true
  - name: kafka-conf-sasl.kerberos.service.name
    default_value:
        null
    description: >-
        The Kerberos principal name that Kafka runs as. This can be defined either
        in Kafka's JAAS config or in Kafka's config.
    config_group: Kafka Producer SASL Options
    type: "*string"
  - name: kafka-conf-sasl.login.callback.handler.class
    default_value:
        null
    description: >-
        The fully qualified name of a SASL login callback handler class that
        implements the `AuthenticateCallbackHandler` interface.


        For brokers, the login callback handler config must be prefixed with the
        listener prefix and the SASL mechanism name in lower-case.


        For example,
        `listener.name.sasl_ssl.scram-sha-256.sasl.login.callback.handler.class=com.example.CustomScramLoginCallbackHandler`
    config_group: Kafka Producer SASL Options
    type: "*string"
  - name: kafka-conf-sasl.login.class
    default_value:
        null
    description: >-
        The fully qualified name of a class that implements the Login interface. For
        brokers, the login config must be prefixed with the listener prefix and the
        SASL mechanism name in lower-case.


        For example,
        `listener.name.sasl_ssl.scram-sha-256.sasl.login.class=com.example.CustomScramLogin`
    config_group: Kafka Producer SASL Options
    type: "*string"
  - name: kafka-conf-sasl.mechanism
    default_value:
        "GSSAPI"
    description: >-
        SASL mechanism used for client connections. This may be any mechanism for
        which a security provider is available. GSSAPI is the default mechanism.
    config_group: Kafka Producer SASL Options
  - name: kafka-conf-sasl.kerberos.kinit.cmd
    default_value:
        "/usr/bin/kinit"
    description: Kerberos kinit command path.
    config_group: Kafka Producer SASL Options
    type: "*string"
  - name: kafka-conf-sasl.kerberos.min.time.before.relogin
    default_value:
        60000
    description: Login thread sleep time between refresh attempts.
    config_group: Kafka Producer SASL Options
    type: "*int"
  - name: kafka-conf-sasl.kerberos.ticket.renew.jitter
    default_value:
        0.05
    description: Percentage of random jitter added to the renewal time.
    config_group: Kafka Producer SASL Options
    type: "*float"
  - name: kafka-conf-sasl.kerberos.ticket.renew.window.factor
    default_value:
        0.8
    description: >-
        Login thread will sleep until the specified window factor of time from last
        refresh to ticket's expiry has been reached, at which time it will try to
        renew the ticket.
    config_group: Kafka Producer SASL Options
    type: "*float"
  - name: kafka-conf-sasl.login.refresh.buffer.seconds
    default_value:
        300
    description: >-
        The amount of buffer time before credential expiration to maintain when
        refreshing a credential, in seconds.


        If a refresh would otherwise occur closer to expiration than the number of
        buffer seconds then the refresh will be moved up to maintain as much of the
        buffer time as possible.


        Legal values are between `0` and `3600` (1 hour); a default value of `300`
        (5 minutes) is used if no value is specified.


        This value and `sasl.login.refresh.min.period.seconds` are both ignored if
        their sum exceeds the remaining lifetime of a credential.


        Currently applies only to `OAUTHBEARER`.
    config_group: Kafka Producer SASL Options
    type: "*int"
  - name: kafka-conf-sasl.login.refresh.min.period.seconds
    default_value:
        60
    description: >-
        The desired minimum time for the login refresh thread to wait before
        refreshing a credential, in seconds.


        Legal values are between `0` and `900` (15 minutes); a default value of `60`
        (1 minute) is used if no value is specified.


        This value and `sasl.login.refresh.buffer.seconds` are both ignored if their
        sum exceeds the remaining lifetime of a credential.


        Currently applies only to `OAUTHBEARER`.
    config_group: Kafka Producer SASL Options
    type: "*int"
  - name: kafka-conf-sasl.login.refresh.window.factor
    default_value:
        0.8
    description: >-
        Login refresh thread will sleep until the specified window factor relative
        to the credential's lifetime has been reached, at which time it will try to
        refresh the credential.


        Legal values are between `0.5` (50%) and `1.0` (100%) inclusive; a default
        value of `0.8` (80%) is used if no value is specified.


        Currently applies only to `OAUTHBEARER`.
    config_group: Kafka Producer SASL Options
    type: "*float"
  - name: kafka-conf-sasl.login.refresh.window.jitter
    default_value:
        0.05
    description: >-
        The maximum amount of random jitter relative to the credential's lifetime
        that is added to the login refresh thread's sleep time.


        Legal values are between `0` and `0.25` (25%) inclusive; a default value of
        `0.05` (5%) is used if no value is specified.


        Currently applies only to `OAUTHBEARER`.
    config_group: Kafka Producer SASL Options
    type: "*float"
  - name: kafka-conf-batch.size
    default_value:
        null
    description: >-
        The producer will attempt to batch records together into fewer requests
        whenever multiple records are being sent to the same partition. This helps
        performance on both the client and the server. This configuration controls
        the default batch size in bytes.


        No attempt will be made to batch records larger than this size.


        Requests sent to brokers will contain multiple batches, one for each
        partition with data available to be sent.


        A small batch size will make batching less common and may reduce throughput
        (a batch size of zero will disable batching entirely). A very large batch
        size may use memory a bit more wastefully as we will always allocate a
        buffer of the specified batch size in anticipation of additional records.
    config_group: Kafka Producer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-client.dns.lookup
    default_value:
        "use_all_dns_ips"
    description: >-
        Controls how the client uses DNS lookups: - `use_all_dns_ips`: Connect to
        each returned IP address in sequence until a successful connection is
        established. After a disconnection, the next IP is used.


        Once all IPs have been used once, the client resolves the IP(s) from the
        hostname again (both the JVM and the OS cache DNS name lookups, however)

        - `resolve_canonical_bootstrap_servers_only`: Resolve each bootstrap address
          into a list of canonical names. After the bootstrap phase, this behaves the
          same as `use_all_dns_ips`

        - `default`: (deprecated) Attempt to connect to the first IP address
        returned
          by the lookup, even if the lookup returns multiple IP addresses
    config_group: Kafka Producer Medium-Priority Options
    allowed_values:
      - "default"
      - "use_all_dns_ips"
      - "resolve_canonical_bootstrap_servers_only"
  - name: kafka-conf-client.id
    default_value:
        null
    description: >-
        An id string to pass to the server when making requests. The purpose of this
        is to be able to track the source of requests beyond just ip/port by
        allowing a logical application name to be included in server-side request
        logging.
    config_group: Kafka Producer Medium-Priority Options
    type: "*string"
  - name: kafka-conf-connections.max.idle.ms
    default_value:
        540000
    description: >-
        Close idle connections after the number of milliseconds specified by this
        config.
    config_group: Kafka Producer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-delivery.timeout.ms
    default_value:
        null
    description: >-
        An upper bound on the time to report success or failure after a call to
        `send()` returns. This limits the total time that a record will be delayed
        prior to sending, the time to await acknowledgement from the broker (if
        expected), and the time allowed for retriable send failures.


        The producer may report failure to send a record earlier than this config if
        either an unrecoverable error is encountered, the retries have been
        exhausted, or the record is added to a batch which reached an earlier
        delivery expiration deadline.


        The value of this config should be greater than or equal to the sum of
        `request.timeout.ms` and `linger.ms`.
    config_group: Kafka Producer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-linger.ms
    default_value:
        null
    description: >-
        The producer groups together any records that arrive in between request
        transmissions into a single batched request. Normally this occurs only under
        load when records arrive faster than they can be sent out.


        However in some circumstances the client may want to reduce the number of
        requests even under moderate load. This setting accomplishes this by adding
        a small amount of artificial delay—that is, rather than immediately sending
        out a record the producer will wait for up to the given delay to allow other
        records to be sent so that the sends can be batched together.


        This can be thought of as analogous to Nagle's algorithm in TCP. This
        setting gives the upper bound on the delay for batching: once we get
        `batch.size` worth of records for a partition it will be sent immediately
        regardless of this setting, however if we have fewer than this many bytes
        accumulated for this partition we will 'linger' for the specified time
        waiting for more records to show up.


        This setting defaults to `0` (i.e. no delay). Setting `linger.ms=5`, for
        example, would have the effect of reducing the number of requests sent but
        would add up to `5ms` of latency to records sent in the absence of load.
    config_group: Kafka Producer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-max.block.ms
    default_value:
        null
    description: >-
        The configuration controls how long `KafkaProducer.send()` and
        `KafkaProducer.partitionsFor()` will block.


        These methods can be blocked either because the buffer is full or metadata
        is unavailable.


        Blocking in the user-supplied serializers or partitioner will not be counted
        against this timeout.
    config_group: Kafka Producer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-max.request.size
    default_value:
        null
    description: >-
        The maximum size of a request in bytes. This setting will limit the number
        of record batches the producer will send in a single request to avoid
        sending huge requests.


        This is also effectively a cap on the maximum uncompressed record batch
        size.


        Note that the server has its own cap on the record batch size (after
        compression if compression is enabled) which may be different from this.
    config_group: Kafka Producer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-partitioner.class
    default_value:
        "org.apache.kafka.clients.producer.internals.DefaultPartitioner"
    description: >-
        Partitioner class that implements the
        `org.apache.kafka.clients.producer.Partitioner` interface.
    config_group: Kafka Producer Medium-Priority Options
  - name: kafka-conf-receive.buffer.bytes
    default_value:
        null
    description: >-
        The size of the TCP receive buffer (`SO_RCVBUF`) to use when reading data.
        If the value is `-1`, the OS default will be used.
    config_group: Kafka Producer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-proc-request.timeout.ms
    default_value:
        null
    description: >-
        The configuration controls the maximum amount of time the client will wait
        for the response of a request.


        If the response is not received before the timeout elapses the client will
        resend the request if necessary or fail the request if retries are
        exhausted.


        This should be larger than `replica.lag.time.max.ms` (a broker
        configuration) to reduce the possibility of message duplication due to
        unnecessary producer retries.
    config_group: Kafka Producer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-security.protocol
    default_value:
        "PLAINTEXT"
    description: Protocol used to communicate with brokers.
    config_group: Kafka Producer Medium-Priority Options
    allowed_values:
      - "PLAINTEXT"
      - "SSL"
      - "SASL_PLAINTEXT"
      - "SASL_SSL"
  - name: kafka-conf-send.buffer.bytes
    default_value:
        null
    description: >-
        The size of the TCP send buffer (`SO_SNDBUF`) to use when sending data. If
        the value is `-1`, the OS default will be used.
    config_group: Kafka Producer Medium-Priority Options
    type: "*int"
  - name: kafka-conf-enable.idempotence
    default_value:
        false
    description: >-
        When set to `true`, the producer will ensure that exactly one copy of each
        message is written in the stream.


        If `false`, producer retries due to broker failures, etc., may write
        duplicates of the retried message in the stream. Note that enabling
        idempotence requires `max.in.flight.requests.per.connection` to be less than
        or equal to `5`, `retries` to be greater than `0` and `acks` must be 'all'.


        If these values are not explicitly set by the user, suitable values will be
        chosen. If incompatible values are set, a `ConfigException` will be thrown.
    config_group: Kafka Producer Low-Priority Options
    type: bool
  - name: kafka-conf-interceptor.classes
    default_value:
        null
    description: >-
        A comma-separated list of classes to use as interceptors. Implementing the
        `org.apache.kafka.clients.producer.ProducerInterceptor` interface allows you
        to intercept (and possibly mutate) the records received by the producer
        before they are published to the Kafka cluster.


        By default, there are no interceptors.
    config_group: Kafka Producer Low-Priority Options
    type: "*string"
  - name: kafka-conf-max.in.flight.requests.per.connection
    default_value:
        5
    description: >-
        The maximum number of unacknowledged requests the client will send on a
        single connection before blocking.


        Note that if this setting is greater than `1` and there are failed sends,
        there is a risk of message re-ordering due to retries (if retries are
        enabled).
    config_group: Kafka Producer Low-Priority Options
    type: "*int"
  - name: kafka-conf-metadata.max.age.ms
    default_value:
        300000
    description: >-
        The period of time in milliseconds after which we force a refresh of
        metadata even if we haven't seen any partition leadership changes to
        proactively discover any new brokers or partitions.
    config_group: Kafka Producer Low-Priority Options
    type: "*int"
  - name: kafka-conf-metadata.max.idle.ms
    default_value:
        300000
    description: >-
        Controls how long the producer will cache metadata for a topic that's idle.


        If the elapsed time since a topic was last produced to exceeds the metadata
        idle duration, then the topic's metadata is forgotten and the next access to
        it will force a metadata fetch request.
    config_group: Kafka Producer Low-Priority Options
    type: "*int"
  - name: kafka-conf-metric.reporters
    default_value:
        null
    description: >-
        A comma-separated list of classes to use as metrics reporters.


        Implementing the `org.apache.kafka.common.metrics.MetricsReporter` interface
        allows plugging in classes that will be notified of new metric creation.


        The `JmxReporter` class is always included to register JMX statistics.
    config_group: Kafka Producer Low-Priority Options
    type: "*string"
  - name: kafka-conf-metrics.num.samples
    default_value:
        null
    description: The number of samples maintained to compute metrics.
    config_group: Kafka Producer Low-Priority Options
    type: "*int"
  - name: kafka-conf-metrics.recording.level
    default_value:
        "INFO"
    description: The highest recording level for metrics.
    config_group: Kafka Producer Low-Priority Options
    allowed_values:
      - "INFO"
      - "DEBUG"
  - name: kafka-conf-metrics.sample.window.ms
    default_value:
        30000
    description: The window of time a metrics sample is computed over.
    config_group: Kafka Producer Low-Priority Options
    type: "*int"
  - name: kafka-conf-reconnect.backoff.max.ms
    default_value:
        1000
    description: >-
        The maximum amount of time in milliseconds to wait when reconnecting to a
        broker that has repeatedly failed to connect.


        If provided, the backoff per host will increase exponentially for each
        consecutive connection failure, up to this maximum.


        After calculating the backoff increase, 20% random jitter is added to avoid
        a connection storms.
    config_group: Kafka Producer Low-Priority Options
    type: "*int"
  - name: kafka-conf-reconnect.backoff.ms
    default_value:
        50
    description: >-
        The base amount of time to wait before attempting to reconnect to a given
        host.


        This avoids repeatedly connecting to a host in a tight loop.


        This backoff applies to all connection attempts by the client to a broker.
    config_group: Kafka Producer Low-Priority Options
    type: "*int"
  - name: kafka-conf-retry.backoff.ms
    default_value:
        100
    description: >-
        The amount of time to wait before attempting to retry a failed request to a
        given topic partition.


        This avoids repeatedly sending requests in a tight loop under some failure
        scenarios.
    config_group: Kafka Producer Low-Priority Options
    type: "*int"
  - name: kafka-conf-security.providers
    default_value:
        null
    description: >-
        A comma-separated list of configurable creator classes each returning a
        provider implementing security algorithms.


        These classes should implement the
        `org.apache.kafka.common.security.auth.SecurityProviderCreator` interface.
    config_group: Kafka Producer Low-Priority Options
    type: "*string"
  - name: kafka-conf-transaction.timeout.ms
    default_value:
        60000
    description: >-
        The maximum amount of time in ms that the transaction coordinator will wait
        for a transaction status update from the producer before proactively
        aborting the ongoing transaction.


        If this value is larger than the `transaction.max.timeout.ms` setting in the
        broker, the request will fail with a `InvalidTransactionTimeout` error.
    config_group: Kafka Producer Low-Priority Options
    type: "*int"
  - name: kafka-conf-transactional.id
    default_value:
        null
    description: >-
        The `TransactionalId` to use for transactional delivery.


        This enables reliability semantics which span multiple producer sessions
        since it allows the client to guarantee that transactions using the same
        `TransactionalId` have been completed prior to starting any new
        transactions.


        If no `TransactionalId` is provided, then the producer is limited to
        idempotent delivery.


        If a `TransactionalId` is configured, `enable.idempotence` is implied.


        By default the `TransactionId` is not configured, which means transactions
        cannot be used.


        Note that, by default, transactions require a cluster of at least three
        brokers which is the recommended setting for production; for development you
        can change this, by adjusting broker setting
        `transaction.state.log.replication.factor`.
    config_group: Kafka Producer Low-Priority Options
    type: "*string"
